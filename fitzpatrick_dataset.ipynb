{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebeac2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fbdaa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_BASE_URL = \"https://clinicaltrials.gov/api/v2/studies\"\n",
    "SEARCH_KEYWORD = 'fitzpatrick'\n",
    "BOSTON_LAT = 42.36\n",
    "BOSTON_LON = -71.06\n",
    "SEARCH_RADIUS_MI = 25\n",
    "STATE_TO_ISOLATE = \"Massachusetts\"\n",
    "\n",
    "RAW_JSON_FILENAME = \"fitzpatrick_search.json\"\n",
    "FINAL_OUTPUT_CSV = \"final_fitzpatrick_trials_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e24b4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Raw data file 'fitzpatrick_search.json' already exists. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "def fetch_clinical_trials_data(api_url, keyword, geo_lat, geo_lon, radius_mi, fields, output_filename):\n",
    "    \"\"\"\n",
    "    Searches the ClinicalTrials.gov API with geographic and eligibility filters\n",
    "    and saves the raw results to a JSON file.\n",
    "    \"\"\"\n",
    "    if os.path.exists(output_filename):\n",
    "        print(f\"[*] Raw data file '{output_filename}' already exists. Skipping download.\")\n",
    "        return\n",
    "\n",
    "    all_studies = []\n",
    "    page_count = 1\n",
    "    next_page_token = None\n",
    "\n",
    "    location_filter = f\"distance({geo_lat},{geo_lon},{radius_mi}mi)\"\n",
    "    eligibility_search = f'AREA[EligibilityCriteria]({keyword})'\n",
    "\n",
    "    params = {\n",
    "        'query.term': eligibility_search,\n",
    "        'filter.geo': location_filter,\n",
    "        'fields': \",\".join(fields),\n",
    "        'pageSize': 100\n",
    "    }\n",
    "\n",
    "    print(\"[*] Starting API query to fetch clinical trial data...\")\n",
    "    print(f\"    - Search Logic: {eligibility_search}\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            if next_page_token:\n",
    "                params['pageToken'] = next_page_token\n",
    "\n",
    "            response = requests.get(api_url, params=params)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "\n",
    "            current_studies = data.get('studies', [])\n",
    "            if current_studies:\n",
    "                all_studies.extend(current_studies)\n",
    "                print(f\"[*] Page {page_count}: Fetched {len(current_studies)} studies. Total so far: {len(all_studies)}\")\n",
    "            else:\n",
    "                print(\"[*] No more studies found, ending search.\")\n",
    "                break\n",
    "\n",
    "            next_page_token = data.get('nextPageToken')\n",
    "            if not next_page_token:\n",
    "                print(\"[*] All pages have been retrieved.\")\n",
    "                break\n",
    "\n",
    "            page_count += 1\n",
    "            time.sleep(0.5)  # Be polite to the API\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"\\n[!] API request failed on page {page_count}: {e}\")\n",
    "            break\n",
    "\n",
    "    if all_studies:\n",
    "        print(f\"\\n[*] Compiling {len(all_studies)} total studies into '{output_filename}'...\")\n",
    "        try:\n",
    "            with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump({'studies': all_studies}, f, ensure_ascii=False, indent=2)\n",
    "            print(f\"[*] Successfully saved raw data to {output_filename}\")\n",
    "        except IOError as e:\n",
    "            print(f\"[!] Error writing to file: {e}\")\n",
    "    else:\n",
    "        print(\"\\n[!] No studies were found to save.\")\n",
    "\n",
    "# --- Execute Data Fetching ---\n",
    "fields_to_get = [\"NCTId\", \"protocolSection\", \"resultsSection\"]\n",
    "fetch_clinical_trials_data(API_BASE_URL, SEARCH_KEYWORD, BOSTON_LAT, BOSTON_LON, SEARCH_RADIUS_MI, fields_to_get, RAW_JSON_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb900c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "def parse_eligibility_criteria(study_record, keyword):\n",
    "    \"\"\"\n",
    "    Finds sentences mentioning a keyword in the eligibility criteria.\n",
    "    Returns a list of dictionaries, each containing the sentence and a boolean\n",
    "    indicating if it's from the exclusion section.\n",
    "    \"\"\"\n",
    "    eligibility_text = study_record.get('protocolSection', {}).get('eligibilityModule', {}).get('eligibilityCriteria', '')\n",
    "    if not eligibility_text:\n",
    "        return []\n",
    "\n",
    "    # Split criteria into inclusion and exclusion parts\n",
    "    parts = re.split(r'exclusion criteria', eligibility_text, flags=re.IGNORECASE)\n",
    "    inclusion_text = parts[0]\n",
    "    exclusion_text = parts[1] if len(parts) > 1 else \"\"\n",
    "\n",
    "    found_sentences = []\n",
    "\n",
    "    # Search inclusion text\n",
    "    for sentence in re.split(r'[.\\n]', inclusion_text):\n",
    "        if keyword in sentence.lower() and sentence.strip():\n",
    "            found_sentences.append({'sentence': sentence.strip(), 'is_exclusion': False})\n",
    "\n",
    "    # Search exclusion text\n",
    "    if exclusion_text:\n",
    "        for sentence in re.split(r'[.\\n]', exclusion_text):\n",
    "            if keyword in sentence.lower() and sentence.strip():\n",
    "                found_sentences.append({'sentence': sentence.strip(), 'is_exclusion': True})\n",
    "\n",
    "    return found_sentences\n",
    "\n",
    "\n",
    "def extract_and_standardize_scores(sentence):\n",
    "    \"\"\"\n",
    "    Analyzes a sentence to extract and format Fitzpatrick scores.\n",
    "    Returns a dictionary containing a readable score and binary flags for each type.\n",
    "    \"\"\"\n",
    "    if not isinstance(sentence, str):\n",
    "        return {}\n",
    "\n",
    "    text = sentence.lower()\n",
    "    standardized = {'Type_I': 0, 'Type_II': 0, 'Type_III': 0, 'Type_IV': 0, 'Type_V': 0, 'Type_VI': 0}\n",
    "    result = {'extracted_score': 'Not Specified'}\n",
    "    result.update(standardized) # Start with all types as 0\n",
    "\n",
    "    # Rule 1: Filter out irrelevant sentences\n",
    "    if any(word in text for word in ['wrinkle', 'severity', 'questionnaire']):\n",
    "        result['extracted_score'] = 'Not a Skin Type Score'\n",
    "        return result\n",
    "\n",
    "    # Rule 2: Handle 'all' or 'any'\n",
    "    if 'all' in text or 'any' in text:\n",
    "        result.update({k: 1 for k in standardized})\n",
    "        result['extracted_score'] = 'All'\n",
    "        return result\n",
    "\n",
    "    # --- Score Parsing Logic ---\n",
    "    roman_map = {'I': 1, 'II': 2, 'III': 3, 'IV': 4, 'V': 5, 'VI': 6}\n",
    "    to_roman_map = {v: k for k, v in roman_map.items()}\n",
    "\n",
    "    # Helper function to safely convert Roman or Arabic numerals to an integer\n",
    "    def _to_int(num_str):\n",
    "        if num_str.isdigit():\n",
    "            return int(num_str)\n",
    "        return roman_map.get(num_str.upper())\n",
    "\n",
    "    # Find all Roman and Arabic numerals\n",
    "    numerals_found = re.findall(r'\\b(vi|v|iv|iii|ii|i|[1-6])\\b', text)\n",
    "    range_match = re.search(r'\\b([ivx\\d]+)\\s*(?:-|to|through)\\s*([ivx\\d]+)\\b', text)\n",
    "\n",
    "    if range_match and len(numerals_found) >= 2:\n",
    "        # **FIXED LOGIC HERE**\n",
    "        start_num = _to_int(numerals_found[0])\n",
    "        end_num = _to_int(numerals_found[-1])\n",
    "\n",
    "        if start_num and end_num and start_num < end_num:\n",
    "            for i in range(start_num, end_num + 1):\n",
    "                standardized[f\"Type_{to_roman_map[i]}\"] = 1\n",
    "            result['extracted_score'] = f\"{to_roman_map[start_num]}-{to_roman_map[end_num]}\"\n",
    "\n",
    "    elif numerals_found:\n",
    "        unique_scores = sorted(list(set(_to_int(n) for n in numerals_found)))\n",
    "        roman_scores = []\n",
    "        for score in unique_scores:\n",
    "            roman_version = to_roman_map[score]\n",
    "            standardized[f\"Type_{roman_version}\"] = 1\n",
    "            roman_scores.append(roman_version)\n",
    "        result['extracted_score'] = \", \".join(roman_scores)\n",
    "\n",
    "    result.update(standardized)\n",
    "    return result\n",
    "\n",
    "\n",
    "def extract_study_details(study_record, state_to_isolate):\n",
    "    \"\"\"\n",
    "    Extracts locations, status, and race demographics from a study record.\n",
    "    \"\"\"\n",
    "    details = {\n",
    "        'status': \"N/A\",\n",
    "        f'{state_to_isolate}_facilities': \"\",\n",
    "        'other_facilities': \"\",\n",
    "    }\n",
    "\n",
    "    protocol = study_record.get('protocolSection', {})\n",
    "    if not protocol:\n",
    "        return details\n",
    "\n",
    "    # --- Extract Status ---\n",
    "    details['status'] = protocol.get('statusModule', {}).get('overallStatus', 'N/A')\n",
    "\n",
    "    # --- Extract Locations ---\n",
    "    iso_locs, other_locs = [], []\n",
    "    locations = protocol.get('contactsLocationsModule', {}).get('locations', [])\n",
    "    for loc in locations:\n",
    "        facility_str = f\"{loc.get('facility', 'N/A')} ({loc.get('city', 'N/A')}, {loc.get('state', 'N/A')})\"\n",
    "        if loc.get('state') == state_to_isolate:\n",
    "            iso_locs.append(facility_str)\n",
    "        else:\n",
    "            other_locs.append(facility_str)\n",
    "    details[f'{state_to_isolate}_facilities'] = \"; \".join(iso_locs) if iso_locs else \"\"\n",
    "    details['other_facilities'] = \"; \".join(other_locs) if other_locs else \"\"\n",
    "\n",
    "    # --- Extract Race Demographics ---\n",
    "    race_counts = defaultdict(int)\n",
    "    results = study_record.get('resultsSection', {})\n",
    "    if results:\n",
    "        baseline_measures = results.get('baselineCharacteristicsModule', {}).get('measures', [])\n",
    "        for measure in baseline_measures:\n",
    "            if measure.get('title') == \"Race (NIH/OMB)\":\n",
    "                for category in measure.get('classes', [{}])[0].get('categories', []):\n",
    "                    race_title = category.get('title')\n",
    "                    total_count = sum(int(m.get('value', 0)) for m in category.get('measurements', []))\n",
    "                    if race_title:\n",
    "                        race_counts[f\"Race_{race_title.replace(' ', '_')}\"] = total_count\n",
    "\n",
    "    details.update(race_counts)\n",
    "    return details\n",
    "\n",
    "print(\"Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0c92c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Loaded 49 studies from 'fitzpatrick_search.json'.\n",
      "[*] Dropped 2 rows that were not skin type scores.\n",
      "[*] Converted race demographic columns to integer type.\n",
      "[*] Reordered columns to place 'other_facilities' at the end.\n",
      "\n",
      "[*] Success! Final dataset with 46 rows saved to 'final_fitzpatrick_trials_dataset.csv'.\n",
      "\n",
      "--- Final Data Preview ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nctId</th>\n",
       "      <th>extracted_score</th>\n",
       "      <th>Type_I</th>\n",
       "      <th>Type_II</th>\n",
       "      <th>Type_III</th>\n",
       "      <th>Type_IV</th>\n",
       "      <th>Type_V</th>\n",
       "      <th>Type_VI</th>\n",
       "      <th>status</th>\n",
       "      <th>Massachusetts_facilities</th>\n",
       "      <th>Race_American_Indian_or_Alaska_Native</th>\n",
       "      <th>Race_Asian</th>\n",
       "      <th>Race_Native_Hawaiian_or_Other_Pacific_Islander</th>\n",
       "      <th>Race_Black_or_African_American</th>\n",
       "      <th>Race_White</th>\n",
       "      <th>Race_More_than_one_race</th>\n",
       "      <th>Race_Unknown_or_Not_Reported</th>\n",
       "      <th>other_facilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT01559922</td>\n",
       "      <td>All</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>Call Suneva for Info (Wellesley, Massachusetts)</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Call Suneva for Info (Beverly Hills, Californi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCT00836342</td>\n",
       "      <td>I-IV</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>Clinical Unit for Research Trials in Skin - MG...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCT05411484</td>\n",
       "      <td>All</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ACTIVE_NOT_RECRUITING</td>\n",
       "      <td>MGH Clinical Unit for Research Trials And Outc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCT01754233</td>\n",
       "      <td>III-IV</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>Skin Care Physicians (Chestnut Hill, Massachus...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCT01438047</td>\n",
       "      <td>I-VI</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>WITHDRAWN</td>\n",
       "      <td>BWH (Boston, Massachusetts)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         nctId extracted_score  Type_I  Type_II  Type_III  Type_IV  Type_V  \\\n",
       "0  NCT01559922             All       1        1         1        1       1   \n",
       "1  NCT00836342            I-IV       1        1         1        1       0   \n",
       "2  NCT05411484             All       1        1         1        1       1   \n",
       "3  NCT01754233          III-IV       0        0         1        1       0   \n",
       "4  NCT01438047            I-VI       1        1         1        1       1   \n",
       "\n",
       "   Type_VI                 status  \\\n",
       "0        1              COMPLETED   \n",
       "1        0              COMPLETED   \n",
       "2        1  ACTIVE_NOT_RECRUITING   \n",
       "3        0              COMPLETED   \n",
       "4        1              WITHDRAWN   \n",
       "\n",
       "                            Massachusetts_facilities  \\\n",
       "0    Call Suneva for Info (Wellesley, Massachusetts)   \n",
       "1  Clinical Unit for Research Trials in Skin - MG...   \n",
       "2  MGH Clinical Unit for Research Trials And Outc...   \n",
       "3  Skin Care Physicians (Chestnut Hill, Massachus...   \n",
       "4                        BWH (Boston, Massachusetts)   \n",
       "\n",
       "   Race_American_Indian_or_Alaska_Native  Race_Asian  \\\n",
       "0                                      4          16   \n",
       "1                                      0           6   \n",
       "2                                      0           0   \n",
       "3                                      0           0   \n",
       "4                                      0           0   \n",
       "\n",
       "   Race_Native_Hawaiian_or_Other_Pacific_Islander  \\\n",
       "0                                               2   \n",
       "1                                               0   \n",
       "2                                               0   \n",
       "3                                               0   \n",
       "4                                               0   \n",
       "\n",
       "   Race_Black_or_African_American  Race_White  Race_More_than_one_race  \\\n",
       "0                              56         216                        0   \n",
       "1                               2         152                        2   \n",
       "2                               0           0                        0   \n",
       "3                               0           0                        0   \n",
       "4                               0           0                        0   \n",
       "\n",
       "   Race_Unknown_or_Not_Reported  \\\n",
       "0                             0   \n",
       "1                             0   \n",
       "2                             0   \n",
       "3                             0   \n",
       "4                             0   \n",
       "\n",
       "                                    other_facilities  \n",
       "0  Call Suneva for Info (Beverly Hills, Californi...  \n",
       "1                                                     \n",
       "2                                                     \n",
       "3                                                     \n",
       "4                                                     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main_processing_pipeline():\n",
    "    \"\"\"\n",
    "    Main function to run the entire data processing and enrichment pipeline.\n",
    "    \"\"\"\n",
    "    # --- 1. Load Raw Data ---\n",
    "    try:\n",
    "        with open(RAW_JSON_FILENAME, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        studies = data.get('studies', [])\n",
    "        print(f\"[*] Loaded {len(studies)} studies from '{RAW_JSON_FILENAME}'.\")\n",
    "    except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "        print(f\"[!] Error loading raw JSON file: {e}. Please run Cell 3 to fetch the data.\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Process Each Study ---\n",
    "    processed_rows = []\n",
    "    \n",
    "    for study in studies:\n",
    "        nct_id = study.get('protocolSection', {}).get('identificationModule', {}).get('nctId', 'N/A')\n",
    "        eligibility_sentences = parse_eligibility_criteria(study, SEARCH_KEYWORD)\n",
    "        study_details = extract_study_details(study, STATE_TO_ISOLATE)\n",
    "\n",
    "        if not eligibility_sentences:\n",
    "            continue\n",
    "            \n",
    "        for sent_info in eligibility_sentences:\n",
    "            if sent_info['is_exclusion']:\n",
    "                continue\n",
    "\n",
    "            sentence = sent_info['sentence']\n",
    "            row = {'nctId': nct_id}\n",
    "            row.update(extract_and_standardize_scores(sentence))\n",
    "            row.update(study_details)\n",
    "            processed_rows.append(row)\n",
    "\n",
    "    if not processed_rows:\n",
    "        print(\"[!] No studies with the specified keyword in inclusion criteria were found.\")\n",
    "        return\n",
    "        \n",
    "    # --- 3. Create and Clean DataFrame ---\n",
    "    df = pd.DataFrame(processed_rows)\n",
    "\n",
    "    # Filter out rows that are not about skin type scores\n",
    "    initial_rows = len(df)\n",
    "    df_final = df[df['extracted_score'] != 'Not a Skin Type Score'].copy()\n",
    "    print(f\"[*] Dropped {initial_rows - len(df_final)} rows that were not skin type scores.\")\n",
    "\n",
    "    # --- Convert race columns to numeric types for calculations ---\n",
    "    race_cols = [col for col in df_final.columns if col.startswith('Race_')]\n",
    "    for col in race_cols:\n",
    "        # Coerce errors will turn non-numbers (like empty strings) into NaN\n",
    "        df_final[col] = pd.to_numeric(df_final[col], errors='coerce').fillna(0).astype(int)\n",
    "    print(\"[*] Converted race demographic columns to integer type.\")\n",
    "\n",
    "    # --- Reorder columns to place 'other_facilities' last ---\n",
    "    cols = df_final.columns.tolist()\n",
    "    if 'other_facilities' in cols:\n",
    "        cols.remove('other_facilities')\n",
    "        cols.append('other_facilities')\n",
    "        df_final = df_final[cols]\n",
    "        print(\"[*] Reordered columns to place 'other_facilities' at the end.\")\n",
    "\n",
    "    # --- 4. Save Final CSV ---\n",
    "    try:\n",
    "        df_final.to_csv(FINAL_OUTPUT_CSV, index=False, encoding='utf-8')\n",
    "        print(f\"\\n[*] Success! Final dataset with {len(df_final)} rows saved to '{FINAL_OUTPUT_CSV}'.\")\n",
    "        print(\"\\n--- Final Data Preview ---\")\n",
    "        display(df_final.head())\n",
    "    except IOError as e:\n",
    "        print(f\"[!] Error writing final CSV file: {e}\")\n",
    "\n",
    "# --- Run the Pipeline ---\n",
    "main_processing_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
